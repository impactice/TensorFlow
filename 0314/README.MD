# ì´ë¯¸ì§€ 
## ì»¨ë³¼ë£¨ì…”ë„ ì‹ ê²½ë§(Convolutional_Neural_Network) 

```
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Load and preprocess CIFAR-10 dataset
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Plot sample images
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# Build CNN model
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))  # Output layer for 10 classes

# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data=(test_images, test_labels))

# Plot training results
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.show()

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f"Test accuracy: {test_acc:.4f}")
```

## ğŸ§  TensorFlow CIFAR-10 CNN ì„¤ëª…

ì´ ë¬¸ì„œëŠ” TensorFlowë¥¼ ì‚¬ìš©í•´ CIFAR-10 ë°ì´í„°ì…‹ì„ ë¶„ë¥˜í•˜ëŠ” CNN ëª¨ë¸ì˜ ì „ì²´ íë¦„ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

---

### 1ï¸âƒ£ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
```python
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
```
- TensorFlowì™€ Kerasë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì„ ì„¤ê³„í•˜ê³ , matplotlibë¡œ ì´ë¯¸ì§€ ì‹œê°í™”ë¥¼ í•©ë‹ˆë‹¤ 

### 2ï¸âƒ£ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì •ê·œí™” 
```python
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0
``` 
- CIFAR-10 ë°ì´í„°ì…‹ì€ 10ê°€ì§€ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ 32x32 í¬ê¸°ì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤ 
- í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”í•´ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì…ë‹ˆë‹¤ 

### 3ï¸âƒ£ í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ ë° ì´ë¯¸ì§€ ì‹œê°í™” 
```python
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([]), plt.yticks([]), plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()
```
- í•™ìŠµ ë°ì´í„° ì¤‘ 25ì¥ì„ ë¬´ì‘ìœ„ë¡œ ì‹œê°í™”í•˜ì—¬ ë°ì´í„°ê°€ ì˜ ë¡œë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤ 

### 4ï¸âƒ£ CNN ëª¨ë¸ ì •ì˜ 
```python
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))
```
- Conv2Dì™€ MaxPooling ê³„ì¸µì„ ë°˜ë³µí•˜ì—¬ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤
- Flattenì„ ì‚¬ìš©í•´ 1ì°¨ì› ë²¡í„°ë¡œ ë§Œë“  í›„, Dense ì¸µì„ í†µí•´ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤

### 5ï¸âƒ£ ëª¨ë¸ ì»´íŒŒì¼  
```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```
- Adam ì˜µí‹°ë§ˆì´ì €, SparseCategoricalCrossentropy ì†ì‹¤í•¨ìˆ˜, accuracy ì§€í‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤  
- from_logits=TrueëŠ” ë§ˆì§€ë§‰ Dense(10)ì—ì„œ softmaxë¥¼ ìƒëµí–ˆê¸° ë•Œë¬¸ì— í•„ìš”í•©ë‹ˆë‹¤

### 6ï¸âƒ£ ëª¨ë¸ í•™ìŠµ 
```python
history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data=(test_images, test_labels))
```
- ëª¨ë¸ì„ í•™ìŠµí•˜ë©° ê²€ì¦ ë°ì´í„°ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤
- history ê°ì²´ë¥¼ í†µí•´ í•™ìŠµ ë„ì¤‘ì˜ ì •í™•ë„ ê¸°ë¡ì„ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### 7ï¸âƒ£ í•™ìŠµ ì •í™•ë„ ì‹œê°í™”  
```python
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.show() 
```
- ì—í­(epoch)ë³„ ì •í™•ë„ ë³€í™”ë¥¼ ì‹œê°í™”í•˜ì—¬ í•™ìŠµì´ ì˜ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤
### 8ï¸âƒ£ ëª¨ë¸ í‰ê°€ 
```python
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f"Test accuracy: {test_acc:.4f}") 
```

- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤
- ì •í™•ë„(test_acc)ê°€ ëª¨ë¸ì˜ ìµœì¢… ë¶„ë¥˜ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤




## ì´ë¯¸ì§€ ë¶„ë¥˜(image classification) 
### ğŸ“Œ ì „ì²´ êµ¬ì¡° ìš”ì•½

1. ë°ì´í„° ë¡œë“œ ë° ì‹œê°í™”
2. ë°ì´í„°ì…‹ ë¶„í•  (train/val)
3. ì „ì²˜ë¦¬ (ì •ê·œí™”, ìºì‹œ, prefetch ë“±)
4. ëª¨ë¸ ì„¤ê³„ì™€ í•™ìŠµ
5. ë°ì´í„° ì¦ê°• ì¶”ê°€ í›„ ì¬í•™ìŠµ
6. ì´ë¯¸ì§€ ì˜ˆì¸¡
7. TensorFlow Lite ëª¨ë¸ ë³€í™˜ ë° ì¶”ë¡  
```python

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import pathlib

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ
dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

# í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ í™•ì¸
roses = list(data_dir.glob('roses/*'))
PIL.Image.open(str(roses[0]))
PIL.Image.open(str(roses[1]))

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
batch_size = 32
img_height = 180
img_width = 180

# ë°ì´í„°ì…‹ ë¡œë“œ (í›ˆë ¨/ê²€ì¦)
train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

# ì‹œê°í™”
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

# ìµœì í™” ì„¤ì •
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# ì •ê·œí™” ë ˆì´ì–´
normalization_layer = layers.Rescaling(1./255)

# ê°„ë‹¨í•œ ëª¨ë¸ ì •ì˜
num_classes = len(class_names)
model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.summary()

# í•™ìŠµ
epochs = 10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

# í•™ìŠµ ì‹œê°í™”
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# ë°ì´í„° ì¦ê°• ì ìš©í•œ ëª¨ë¸
data_augmentation = keras.Sequential([
  layers.RandomFlip("horizontal", input_shape=(img_height, img_width, 3)),
  layers.RandomRotation(0.1),
  layers.RandomZoom(0.1),
])

model = Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes, name="outputs")
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.summary()

epochs = 15
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

# ìƒˆ ì´ë¯¸ì§€ ì˜ˆì¸¡
sunflower_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg"
sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)

img = tf.keras.utils.load_img(sunflower_path, target_size=(img_height, img_width))
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])
print("This image most likely belongs to {} with a {:.2f} percent confidence."
      .format(class_names[np.argmax(score)], 100 * np.max(score)))

# TensorFlow Lite ë³€í™˜
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

interpreter = tf.lite.Interpreter(model_path='model.tflite')
interpreter.allocate_tensors()
classify_lite = interpreter.get_signature_runner('serving_default')
predictions_lite = classify_lite(sequential_1_input=img_array)['outputs']
score_lite = tf.nn.softmax(predictions_lite)

print("Lite Model: This image most likely belongs to {} with a {:.2f} percent confidence."
      .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite)))
print(np.max(np.abs(predictions - predictions_lite)))
```




---

## âœï¸ 2. ì„¤ëª… ì •ë¦¬ (READMEìš© Markdown)

```markdown
# ğŸŒ¸ Flower Image Classification with TensorFlow

This project trains a CNN model to classify flower images into 5 categories, and demonstrates TensorFlow Lite model conversion for lightweight deployment.

---

## ğŸ§  Summary

| Feature        | Description |
|----------------|-------------|
| **Dataset**    | Flower images (daisy, dandelion, roses, sunflowers, tulips) |
| **Model**      | CNN (Conv2D + MaxPooling + Dense) |
| **Preprocessing** | Rescaling, Shuffle, Prefetch |
| **Augmentation** | Flip, Rotation, Zoom |
| **Loss**       | SparseCategoricalCrossentropy (with logits) |
| **Optimizer**  | Adam |
| **Deployment** | TensorFlow Lite (.tflite) conversion |

---

## ğŸ—ï¸ Architecture

```text
Input Image â†’ Data Augmentation â†’ Conv2D Layers â†’ MaxPooling â†’ Dropout â†’ Flatten â†’ Dense â†’ Output
